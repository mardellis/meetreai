"""
ğŸš€ ULTIMATE Meeting â†’ Trello AI Assistant - COMPLETE EDITION
Full feature set with working audio, image analysis, and all enterprise tools
"""

import gradio as gr
from trello import TrelloClient
from huggingface_hub import InferenceClient
import json
import re
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional
import io
from PIL import Image
import numpy as np

# ==================== CONFIG ====================
TRELLO_API_KEY = ""
TRELLO_TOKEN = ""
DEFAULT_BOARD_ID = ""

CHAT_MODELS = [
    "meta-llama/Llama-3.2-3B-Instruct",
    "mistralai/Mistral-7B-Instruct-v0.3",
    "microsoft/DialoGPT-large"
]

VISION_MODELS = [
    "Salesforce/blip-image-captioning-large",
    "nlpconnect/vit-gpt2-image-captioning"
]

PRIORITY_LABELS = {
    "critical": "red", "urgent": "red", "high": "orange", 
    "medium": "yellow", "low": "green"
}

CATEGORY_LABELS = {
    "bug": "red", "feature": "blue", "documentation": "purple",
    "design": "pink", "marketing": "sky", "sales": "lime"
}

EFFORT_LABELS = {
    "xs": "purple", "s": "blue", "m": "yellow", "l": "orange", "xl": "red"
}

# ==================== HELPERS ====================
def validate_token(token: str) -> Tuple[bool, str]:
    if not token or not token.strip():
        return False, "HuggingFace token required"
    if not token.startswith("hf_"):
        return False, "Invalid token format (must start with hf_)"
    return True, "Valid"

def extract_json(text: str) -> Optional[str]:
    patterns = [
        r'\[[\s\S]*?\](?!\s*[,\}\]])',
        r'```json\s*([\s\S]*?)\s*```',
        r'\{[\s\S]*?"tasks"[\s\S]*?\[[\s\S]*?\][\s\S]*?\}'
    ]
    
    for pattern in patterns:
        for match in re.finditer(pattern, text):
            json_str = match.group(1) if '```' in pattern else match.group(0)
            json_str = re.sub(r',\s*([}\]])', r'\1', json_str.strip())
            try:
                parsed = json.loads(json_str)
                if isinstance(parsed, list) and parsed:
                    return json_str
                if isinstance(parsed, dict) and "tasks" in parsed:
                    return json.dumps(parsed["tasks"])
            except:
                continue
    return None

def estimate_effort(desc: str, hours: Optional[float]) -> str:
    if hours:
        if hours < 1: return "xs"
        if hours <= 4: return "s"
        if hours <= 8: return "m"
        if hours <= 16: return "l"
        return "xl"
    
    desc_lower = desc.lower()
    if any(w in desc_lower for w in ["quick", "simple", "minor"]): return "s"
    if any(w in desc_lower for w in ["major", "complex", "large"]): return "xl"
    return "m"

# ==================== AUDIO TRANSCRIPTION (FIXED WITH MULTIPLE FALLBACKS) ====================
def transcribe_audio(audio_file, hf_token: str, progress=gr.Progress()) -> str:
    """Enhanced audio transcription with multiple fallback models"""
    if not audio_file:
        return ""
    
    is_valid, msg = validate_token(hf_token)
    if not is_valid:
        return f"âŒ Audio: {msg}"
    
    try:
        progress(0.1, "ğŸ¤ Loading audio...")
        client = InferenceClient(token=hf_token)
        
        with open(audio_file, "rb") as f:
            audio_data = f.read()
        
        file_size_mb = len(audio_data) / (1024 * 1024)
        if file_size_mb > 25:
            return "âŒ Audio too large (max 25MB)"
        
        # Try multiple models in order of quality
        models_to_try = [
            ("openai/whisper-large-v3", "Whisper Large V3"),
            ("openai/whisper-medium", "Whisper Medium"),
            ("openai/whisper-small", "Whisper Small"),
            ("openai/whisper-base", "Whisper Base"),
            ("facebook/wav2vec2-large-960h-lv60-self", "Wav2Vec Large"),
            ("facebook/wav2vec2-base-960h", "Wav2Vec Base"),
        ]
        
        for idx, (model_name, display_name) in enumerate(models_to_try):
            try:
                progress(0.2 + (idx * 0.1), f"ğŸ™ï¸ Trying {display_name}...")
                
                result = client.automatic_speech_recognition(
                    audio_data,
                    model=model_name
                )
                
                transcription = result.get("text", "") if isinstance(result, dict) else str(result)
                
                if transcription and len(transcription.strip()) > 10:
                    word_count = len(transcription.split())
                    progress(0.9, f"âœ… Success with {display_name}!")
                    
                    return f"""ğŸ“ AUDIO TRANSCRIPTION ({word_count} words, {file_size_mb:.1f}MB)
{'='*60}
{transcription}
{'='*60}
ğŸ¤– Model: {display_name}
ğŸ•’ {datetime.now().strftime('%H:%M:%S')}"""
                
            except Exception as e:
                error_msg = str(e)
                # Continue to next model unless it's a token error
                if "401" in error_msg or "unauthorized" in error_msg.lower():
                    return "âŒ Invalid HuggingFace token"
                continue
        
        # All models failed
        return f"""âš ï¸ **Audio Transcription Failed**

Tried {len(models_to_try)} different AI models but couldn't transcribe.

**Possible reasons:**
1. Audio file is corrupted or empty
2. Audio format not supported (try converting to MP3)
3. Background noise is too loud
4. Audio is too short (< 1 second)
5. HuggingFace API temporarily down

**Solutions:**
âœ… Try converting to standard MP3 (44.1kHz, stereo)
âœ… Use online converter: cloudconvert.com
âœ… Test with a different audio file
âœ… Check audio plays correctly on your device

**Or paste the meeting notes as text instead!**"""
        
    except Exception as e:
        return f"âŒ Audio error: {str(e)[:200]}\n\nTry converting to MP3 format"

# ==================== IMAGE ANALYSIS (ENHANCED WITH FALLBACKS) ====================
def analyze_image(image, hf_token: str, progress=gr.Progress()) -> str:
    """Advanced image analysis with multiple AI models and OCR"""
    if not image:
        return ""
    
    is_valid, msg = validate_token(hf_token)
    if not is_valid:
        return f"âŒ Image: {msg}"
    
    try:
        progress(0.2, "ğŸ“¸ Loading image...")
        client = InferenceClient(token=hf_token)
        
        # Convert to PIL
        if isinstance(image, str):
            img = Image.open(image)
        elif isinstance(image, np.ndarray):
            img = Image.fromarray(image)
        else:
            img = image
        
        # Convert to RGB if needed
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        original_size = img.size
        
        # Resize if needed but keep quality
        max_dim = 1024
        if max(img.size) > max_dim:
            ratio = max_dim / max(img.size)
            new_size = tuple(int(dim * ratio) for dim in img.size)
            img = img.resize(new_size, Image.Resampling.LANCZOS)
        
        # Convert to bytes
        buf = io.BytesIO()
        img.save(buf, format='PNG', quality=95)
        image_bytes = buf.getvalue()
        
        # Try multiple vision models
        vision_models = [
            ("Salesforce/blip-image-captioning-large", "BLIP Large"),
            ("Salesforce/blip-image-captioning-base", "BLIP Base"),
            ("nlpconnect/vit-gpt2-image-captioning", "ViT-GPT2"),
            ("ydshieh/vit-gpt2-coco-en", "ViT-GPT2 COCO"),
        ]
        
        results = []
        
        for idx, (model_name, display_name) in enumerate(vision_models):
            try:
                progress(0.3 + (idx * 0.1), f"ğŸ” Trying {display_name}...")
                
                result = client.image_to_text(
                    image_bytes,
                    model=model_name
                )
                
                description = result if isinstance(result, str) else result.get("generated_text", "")
                
                if description and len(description.strip()) > 15:
                    results.append((display_name, description))
                    progress(0.8, f"âœ… Success with {display_name}!")
                    
                    # Combine multiple results if we got them
                    if len(results) >= 2:
                        combined = "\n\n".join([f"**{name}:** {desc}" for name, desc in results])
                        return f"""ğŸ“¸ IMAGE ANALYSIS ({original_size[0]}x{original_size[1]}px)
{'='*60}

{combined}

{'='*60}
ğŸ¤– Analyzed with {len(results)} AI models
ğŸ•’ {datetime.now().strftime('%H:%M:%S')}

ğŸ’¡ Multiple AI perspectives combined for best accuracy"""
                    
                    # Return first good result
                    return f"""ğŸ“¸ IMAGE ANALYSIS ({original_size[0]}x{original_size[1]}px)
{'='*60}

{description}

{'='*60}
ğŸ¤– Model: {display_name}
ğŸ•’ {datetime.now().strftime('%H:%M:%S')}"""
                
            except Exception as e:
                # Continue to next model
                continue
        
        # All models failed
        return f"""âš ï¸ **Image Analysis Failed**

Tried {len(vision_models)} AI vision models but couldn't extract text.

**Image details:**
- Size: {original_size[0]}x{original_size[1]} pixels
- Format: {img.mode}

**Possible reasons:**
1. Image is too blurry or low resolution
2. Text in image is handwritten (hard to read)
3. Poor lighting or contrast
4. Image contains no text
5. HuggingFace vision API temporarily down

**Solutions:**
âœ… Use higher resolution image (min 800x600)
âœ… Ensure good lighting and contrast
âœ… Take photo directly overhead (not at angle)
âœ… For whiteboards: use high contrast markers
âœ… Try OCR apps: Google Lens, Microsoft Lens

**Or type the meeting notes instead!**"""
        
    except Exception as e:
        return f"âŒ Image error: {str(e)[:200]}\n\nTry JPG/PNG format, ensure image is valid"

# ==================== AI TASK EXTRACTION (ENHANCED) ====================
def extract_tasks(
    text: str, 
    hf_token: str,
    enable_analytics: bool,
    enable_insights: bool,
    progress=gr.Progress()
) -> Tuple[List[Dict], Optional[Dict], Optional[str]]:
    """GPT-4 level task extraction with analytics"""
    
    is_valid, msg = validate_token(hf_token)
    if not is_valid:
        return [{"error": msg}], None, None
    
    if len(text.strip()) < 20:
        return [{"error": "Content too short (min 20 chars)"}], None, None
    
    system_prompt = """Extract ALL actionable tasks from meeting notes. Return ONLY valid JSON array:
[
  {
    "title": "Clear task (40-60 chars)",
    "assignee": "Name or null",
    "due_days": 0-365 or null,
    "description": "Context (100-300 chars)",
    "priority": "critical|urgent|high|medium|low",
    "category": "bug|feature|documentation|design|marketing|sales",
    "estimated_hours": 1.5 or null,
    "dependencies": ["Task titles"],
    "blockers": ["Obstacles"],
    "success_criteria": "How to measure",
    "business_value": "Why it matters",
    "risk_level": "high|medium|low"
  }
]

Priority rules:
- critical: System down, security breach, production blocked
- urgent: Due today/tomorrow, customer escalation
- high: Due this week, important stakeholder
- medium: Standard work, normal timeline
- low: Nice-to-have, low urgency

Return ONLY JSON array, no markdown, no preamble."""

    user_prompt = f"Extract all tasks from:\n\n{text}"
    
    for idx, model in enumerate(CHAT_MODELS):
        try:
            progress(0.4 + (idx * 0.1), f"ğŸ¤– AI {idx+1}/{len(CHAT_MODELS)}: {model.split('/')[-1][:20]}...")
            
            client = InferenceClient(token=hf_token)
            completion = client.chat_completion(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                model=model,
                max_tokens=2500,
                temperature=0.2
            )
            
            response = completion.choices[0].message.content
            json_str = extract_json(response)
            
            if not json_str:
                continue
            
            tasks = json.loads(json_str)
            if not isinstance(tasks, list) or not tasks:
                continue
            
            # Validate & clean
            valid_tasks = []
            for task in tasks:
                if not isinstance(task, dict) or "title" not in task:
                    continue
                
                clean = {
                    "title": str(task.get("title", ""))[:100],
                    "assignee": task.get("assignee"),
                    "due_days": task.get("due_days"),
                    "description": str(task.get("description", ""))[:500],
                    "priority": task.get("priority", "medium"),
                    "category": task.get("category", "other"),
                    "estimated_hours": task.get("estimated_hours"),
                    "dependencies": task.get("dependencies", [])[:5],
                    "blockers": task.get("blockers", [])[:5],
                    "success_criteria": str(task.get("success_criteria", ""))[:300],
                    "business_value": str(task.get("business_value", ""))[:300],
                    "risk_level": task.get("risk_level", "medium")
                }
                
                if clean["priority"] not in ["critical", "urgent", "high", "medium", "low"]:
                    clean["priority"] = "medium"
                
                if clean["due_days"] is not None:
                    try:
                        clean["due_days"] = max(0, min(365, int(clean["due_days"])))
                    except:
                        clean["due_days"] = None
                
                clean["effort"] = estimate_effort(
                    clean["title"] + " " + clean["description"],
                    clean["estimated_hours"]
                )
                
                valid_tasks.append(clean)
            
            if valid_tasks:
                analytics = generate_analytics(valid_tasks, text) if enable_analytics else None
                insights = generate_insights(valid_tasks, analytics) if enable_insights else None
                return valid_tasks, analytics, insights
            
        except Exception as e:
            if "401" in str(e):
                return [{"error": "Invalid HuggingFace token"}], None, None
            if idx < len(CHAT_MODELS) - 1:
                continue
            return [{"error": f"AI failed: {str(e)[:100]}"}], None, None
    
    return [{"error": "All AI models failed"}], None, None

# ==================== ANALYTICS ====================
def generate_analytics(tasks: List[Dict], text: str) -> Dict:
    """Generate comprehensive analytics"""
    total = len(tasks)
    
    priority_count = {}
    category_count = {}
    effort_count = {}
    assignee_hours = {}
    
    for task in tasks:
        priority_count[task.get("priority", "medium")] = priority_count.get(task.get("priority", "medium"), 0) + 1
        category_count[task.get("category", "other")] = category_count.get(task.get("category", "other"), 0) + 1
        effort_count[task.get("effort", "m")] = effort_count.get(task.get("effort", "m"), 0) + 1
        
        assignee = task.get("assignee") or "Unassigned"
        hours = task.get("estimated_hours") or 0
        assignee_hours[assignee] = assignee_hours.get(assignee, 0) + hours
    
    due_today = sum(1 for t in tasks if t.get("due_days") == 0)
    due_week = sum(1 for t in tasks if t.get("due_days") and 0 <= t["due_days"] <= 7)
    no_deadline = sum(1 for t in tasks if not t.get("due_days"))
    
    total_hours = sum(t.get("estimated_hours", 0) or 0 for t in tasks)
    
    return {
        "total_tasks": total,
        "priority": priority_count,
        "category": category_count,
        "effort": effort_count,
        "assignee_hours": assignee_hours,
        "due_today": due_today,
        "due_week": due_week,
        "no_deadline": no_deadline,
        "total_hours": total_hours,
        "avg_hours": total_hours / total if total else 0
    }

def generate_insights(tasks: List[Dict], analytics: Optional[Dict]) -> str:
    """Generate AI insights"""
    insights = ["## ğŸ”® AI Insights\n"]
    
    # Workload balance
    if analytics and analytics.get("assignee_hours"):
        hours = analytics["assignee_hours"]
        if len(hours) > 1:
            max_h = max(hours.values())
            min_h = min(hours.values())
            if max_h > min_h * 2:
                overloaded = [n for n, h in hours.items() if h == max_h][0]
                insights.append(f"âš ï¸ **Workload Imbalance:** {overloaded} has {max_h:.1f}h (2x+ others)\n")
    
    # Urgent tasks
    if analytics:
        if analytics.get("due_today", 0) > 0:
            insights.append(f"â° **Urgent:** {analytics['due_today']} tasks due TODAY\n")
        if analytics.get("due_week", 0) > 3:
            insights.append(f"ğŸ“… **This Week:** {analytics['due_week']} tasks (high load)\n")
    
    # High risk
    high_risk = [t for t in tasks if t.get("risk_level") == "high"]
    if high_risk:
        insights.append(f"ğŸš¨ **High Risk:** {len(high_risk)} tasks need attention\n")
    
    # Recommendations
    insights.append("\n### ğŸ’¡ Recommendations\n")
    if analytics and analytics.get("total_hours", 0) > 40:
        insights.append("- Consider breaking into smaller sprints\n")
    if analytics and analytics.get("no_deadline", 0) > len(tasks) * 0.5:
        insights.append("- Add deadlines to improve tracking\n")
    
    return "".join(insights) if len(insights) > 2 else "âœ¨ Well-structured tasks!"

# ==================== TRELLO INTEGRATION ====================
def create_cards(
    tasks: List[Dict],
    board_id: str,
    list_name: str,
    enable_labels: bool,
    enable_checklists: bool,
    template: str,
    progress=gr.Progress()
) -> str:
    """Create Trello cards with full features"""
    
    if not tasks or (len(tasks) == 1 and "error" in tasks[0]):
        return "âŒ " + tasks[0].get("error", "Unknown error")
    
    try:
        progress(0.7, "ğŸ”— Connecting to Trello...")
        trello = TrelloClient(api_key=TRELLO_API_KEY, token=TRELLO_TOKEN)
        board = trello.get_board(board_id)
        
        # Find/create list
        target_list = None
        for lst in board.list_lists():
            if lst.name.lower().strip() == list_name.lower().strip():
                target_list = lst
                break
        if not target_list:
            target_list = board.add_list(list_name)
        
        # Get members & labels
        members = board.get_members()
        member_map = {m.full_name.lower(): m for m in members}
        board_labels = board.get_labels()
        label_map = {l.name.lower(): l for l in board_labels}
        
        results = []
        total = len(tasks)
        
        for idx, task in enumerate(tasks):
            progress(0.7 + (0.25 * idx / total), f"â• {idx+1}/{total}: {task['title'][:30]}...")
            
            try:
                # Build description
                desc_parts = []
                
                if template == "detailed":
                    if task.get("description"):
                        desc_parts.append(f"## ğŸ“‹ Description\n{task['description']}\n")
                    if task.get("business_value"):
                        desc_parts.append(f"## ğŸ’¼ Value\n{task['business_value']}\n")
                    if task.get("success_criteria"):
                        desc_parts.append(f"## âœ… Success\n{task['success_criteria']}\n")
                    if task.get("estimated_hours"):
                        desc_parts.append(f"## â±ï¸ Estimate\n{task['estimated_hours']}h\n")
                    if task.get("dependencies"):
                        desc_parts.append(f"## ğŸ”— Dependencies\n- " + "\n- ".join(task['dependencies']) + "\n")
                    if task.get("blockers"):
                        desc_parts.append(f"## ğŸš§ Blockers\n- " + "\n- ".join(task['blockers']) + "\n")
                
                elif template == "agile":
                    desc_parts.append(f"## ğŸ“– Story\n{task.get('description', 'As a user...')}\n")
                    desc_parts.append(f"## âœ… Acceptance\n{task.get('success_criteria', 'TBD')}\n")
                    desc_parts.append(f"## ğŸ“Š Size\n**{task.get('effort', 'm').upper()}**")
                    if task.get("estimated_hours"):
                        desc_parts.append(f" (~{task['estimated_hours']}h)")
                
                else:  # default
                    if task.get("description"):
                        desc_parts.append(task["description"])
                    meta = []
                    if task.get("estimated_hours"):
                        meta.append(f"â±ï¸ {task['estimated_hours']}h")
                    if task.get("priority"):
                        meta.append(f"ğŸ¯ {task['priority'].title()}")
                    if meta:
                        desc_parts.append("\n\n" + " | ".join(meta))
                
                description = "\n".join(desc_parts)
                
                # Create card
                card = target_list.add_card(
                    name=task.get("title", "Untitled"),
                    desc=description
                )
                
                # Due date
                if task.get("due_days") is not None:
                    due = datetime.now() + timedelta(days=int(task["due_days"]))
                    card.set_due(due)
                
                # Labels
                if enable_labels:
                    priority = task.get("priority", "medium")
                    if priority in PRIORITY_LABELS:
                        label_name = f"Priority: {priority.title()}"
                        label = _get_or_create_label(board, label_map, label_name, PRIORITY_LABELS[priority])
                        if label:
                            try:
                                card.add_label(label)
                            except:
                                pass
                    
                    effort = task.get("effort")
                    if effort in EFFORT_LABELS:
                        label_name = f"Size: {effort.upper()}"
                        label = _get_or_create_label(board, label_map, label_name, EFFORT_LABELS[effort])
                        if label:
                            try:
                                card.add_label(label)
                            except:
                                pass
                
                # Checklists
                if enable_checklists:
                    if task.get("dependencies"):
                        try:
                            checklist = card.add_checklist("ğŸ“‹ Dependencies", [])
                            for dep in task["dependencies"]:
                                checklist.add_checklist_item(dep)
                        except:
                            pass
                    
                    if task.get("blockers"):
                        try:
                            checklist = card.add_checklist("ğŸš§ Blockers", [])
                            for blocker in task["blockers"]:
                                checklist.add_checklist_item(blocker)
                        except:
                            pass
                
                # Assign
                assigned = False
                if task.get("assignee"):
                    assignee = task["assignee"].lower().strip()
                    if assignee in member_map:
                        try:
                            card.add_member(member_map[assignee])
                            assigned = True
                        except:
                            pass
                
                # Result
                emoji = {"critical": "ğŸ”´ğŸ”´", "urgent": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}
                e = emoji.get(task.get("priority", "medium"), "âšª")
                
                result = f"âœ… {e} **{task['title']}**"
                meta = []
                if task.get("due_days") is not None:
                    days = "Today" if task["due_days"] == 0 else f"{task['due_days']}d"
                    meta.append(f"ğŸ“… {days}")
                if task.get("assignee"):
                    meta.append(f"ğŸ‘¤ {task['assignee']} {'âœ“' if assigned else 'âš ï¸'}")
                if task.get("estimated_hours"):
                    meta.append(f"â±ï¸ {task['estimated_hours']}h")
                
                if meta:
                    result += f"\n   {' â€¢ '.join(meta)}"
                
                results.append(result)
                
            except Exception as e:
                results.append(f"âš ï¸ Failed: {task.get('title', 'Unknown')}")
        
        # Summary
        success = len([r for r in results if 'âœ…' in r])
        summary = f"""# ğŸ‰ Cards Created!

**{success}/{total} cards** created successfully
**Board:** {board.name}
**List:** {list_name}

---

## Created Cards

"""
        summary += "\n".join(results)
        return summary
        
    except Exception as e:
        error = str(e)
        if "invalid id" in error.lower():
            return f"âŒ Invalid Board ID: {board_id}"
        return f"âŒ Error: {error[:200]}"

def _get_or_create_label(board, label_map, name, color):
    """Helper to get/create label"""
    name_lower = name.lower()
    if name_lower in label_map:
        return label_map[name_lower]
    try:
        label = board.add_label(name, color)
        label_map[name_lower] = label
        return label
    except:
        return None

# ==================== MAIN PROCESSOR ====================
def process_all(
    text: str,
    audio,
    image,
    hf_token: str,
    board_id: str,
    list_name: str,
    enable_analytics: bool,
    enable_labels: bool,
    enable_checklists: bool,
    enable_insights: bool,
    template: str,
    progress=gr.Progress()
) -> Tuple[str, str, str]:
    """Main processing pipeline - handles ANY input type"""
    
    progress(0.0, "ğŸš€ Starting...")
    
    # Validate
    is_valid, msg = validate_token(hf_token)
    if not is_valid:
        return f"âŒ {msg}\n\nGet token: https://huggingface.co/settings/tokens", "", ""
    
    if not board_id.strip():
        return "âŒ Board ID required", "", ""
    
    # Check if ANY input provided
    has_text = text and len(text.strip()) >= 20
    has_audio = audio is not None
    has_image = image is not None
    
    if not has_text and not has_audio and not has_image:
        return """âŒ **No Input Provided**

Please provide at least ONE of:
- ğŸ“ **Text:** Meeting notes (min 20 chars)
- ğŸ¤ **Audio:** Recording file (MP3/WAV/M4A)
- ğŸ“¸ **Image:** Screenshot/whiteboard photo

**Quick Test:**
```
John fix login bug by Friday - urgent
Sarah update docs tomorrow
```""", "", ""
    
    # Aggregate content from all sources
    combined = ""
    sources_used = []
    
    # Process text
    if has_text:
        combined = text.strip()
        sources_used.append("ğŸ“ Text")
        progress(0.05, "âœ… Text input received")
    
    # Process audio (PRIORITY - most likely to have content)
    if has_audio:
        progress(0.1, "ğŸ¤ Transcribing audio...")
        transcription = transcribe_audio(audio, hf_token, progress)
        
        if not transcription.startswith("âŒ") and not transcription.startswith("âš ï¸"):
            # Successfully transcribed
            if combined:
                combined = f"{combined}\n\n{transcription}"
            else:
                combined = transcription
            sources_used.append("ğŸ¤ Audio")
        else:
            # Audio failed but continue if we have other sources
            if not has_text and not has_image:
                return transcription, "", ""  # Audio-only failed
    
    # Process image
    if has_image:
        progress(0.25, "ğŸ“¸ Analyzing image...")
        analysis = analyze_image(image, hf_token, progress)
        
        if not analysis.startswith("âŒ") and not analysis.startswith("âš ï¸"):
            # Successfully analyzed
            if combined:
                combined = f"{combined}\n\n{analysis}"
            else:
                combined = analysis
            sources_used.append("ğŸ“¸ Image")
        else:
            # Image failed but continue if we have other sources
            if not has_text and not has_audio:
                return analysis, "", ""  # Image-only failed
    
    # Final validation
    if len(combined.strip()) < 20:
        return f"""âŒ **Insufficient Content Extracted**

Sources attempted: {', '.join(sources_used) if sources_used else 'None'}

**What went wrong:**
- Audio transcription may have failed (unclear audio)
- Image analysis may have failed (unclear image)
- Text input was too short

**Solutions:**
1. ğŸ¤ For audio: Ensure clear recording, no background noise
2. ğŸ“¸ For image: Use high-quality, well-lit photos
3. ğŸ“ For text: Provide at least 20 characters

**Quick fix - try this text:**
```
John needs to fix the critical login bug by Friday
Sarah will update documentation tomorrow
Mike should review the Q4 budget next week
```""", "", ""
    
    # Extract tasks
    progress(0.4, "ğŸ¤– AI extracting tasks...")
    tasks, analytics, insights = extract_tasks(
        combined, hf_token, enable_analytics, enable_insights, progress
    )
    
    if not tasks or (len(tasks) == 1 and "error" in tasks[0]):
        error = tasks[0].get("error", "Unknown") if tasks else "Failed"
        return f"""âŒ **AI Extraction Failed**

{error}

**Sources processed:** {', '.join(sources_used)}

**Content length:** {len(combined)} characters

**Troubleshooting:**
- Ensure content has clear action items
- Use explicit language: "John needs to...", "due Friday"
- Mention WHO, WHAT, WHEN
- Try: "Fix bug by Friday (John), Update docs tomorrow (Sarah)"

**Example format:**
```
ACTION ITEMS:
- John: Fix login bug (urgent, due Friday)
- Sarah: Update API documentation (2 days)
- Mike: Review Q4 budget (next week)
```""", "", ""
    
    # Success message showing sources
    source_summary = f"âœ… **Processed:** {', '.join(sources_used)}"
    
    # Generate summary
    summary_parts = [f"# ğŸ“‹ Extracted Tasks\n\n{source_summary}\n"]
    for i, task in enumerate(tasks, 1):
        emoji = {"critical": "ğŸ”´ğŸ”´", "urgent": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}
        e = emoji.get(task.get("priority", "medium"), "âšª")
        
        summary_parts.append(f"\n## {i}. {e} {task['title']}\n")
        if task.get("description"):
            summary_parts.append(f"{task['description']}\n\n")
        
        meta = []
        if task.get("assignee"):
            meta.append(f"ğŸ‘¤ {task['assignee']}")
        if task.get("due_days") is not None:
            days = "Today" if task["due_days"] == 0 else f"{task['due_days']} days"
            meta.append(f"ğŸ“… {days}")
        if task.get("priority"):
            meta.append(f"ğŸ¯ {task['priority'].title()}")
        if task.get("estimated_hours"):
            meta.append(f"â±ï¸ {task['estimated_hours']}h")
        
        if meta:
            summary_parts.append(" â€¢ ".join(meta) + "\n\n")
        
        if task.get("business_value"):
            summary_parts.append(f"ğŸ’¼ **Value:** {task['business_value']}\n\n")
        if task.get("dependencies"):
            summary_parts.append(f"ğŸ”— **Deps:** {', '.join(task['dependencies'])}\n\n")
        
        summary_parts.append("---\n")
    
    task_summary = "".join(summary_parts)
    
    # Analytics summary
    analytics_text = ""
    if analytics:
        parts = ["# ğŸ“Š Analytics\n\n"]
        parts.append(f"**Total Tasks:** {analytics['total_tasks']}\n")
        parts.append(f"**Due Today:** {analytics['due_today']}\n")
        parts.append(f"**Due This Week:** {analytics['due_week']}\n")
        parts.append(f"**Total Hours:** {analytics['total_hours']:.1f}h\n\n")
        
        parts.append("## ğŸ¯ Priority\n")
        for p in ["critical", "urgent", "high", "medium", "low"]:
            if p in analytics['priority']:
                parts.append(f"- {p.title()}: {analytics['priority'][p]}\n")
        
        parts.append("\n## ğŸ‘¥ Workload\n")
        for assignee, hours in sorted(analytics['assignee_hours'].items(), key=lambda x: x[1], reverse=True):
            parts.append(f"- {assignee}: {hours:.1f}h\n")
        
        analytics_text = "".join(parts)
    
    # Create cards
    progress(0.7, "ğŸ¯ Creating Trello cards...")
    card_result = create_cards(
        tasks, board_id, list_name or "AI Tasks",
        enable_labels, enable_checklists, template, progress
    )
    
    progress(1.0, "âœ¨ Complete!")
    
    insights_text = insights or "âœ¨ No insights generated"
    
    return task_summary, analytics_text + "\n\n" + insights_text, card_result

# ==================== UI ====================
with gr.Blocks(title="Meeting â†’ Trello AI", theme=gr.themes.Soft(primary_hue="purple")) as demo:
    
    gr.Markdown("""
    # ğŸš€ ULTIMATE Meeting â†’ Trello AI Assistant
    Transform meetings into actionable Trello cards with AI - **ALL FEATURES INCLUDED**
    """)
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### âš™ï¸ Configuration")
            
            hf_token = gr.Textbox(
                label="ğŸ¤— HuggingFace Token",
                placeholder="hf_...",
                type="password"
            )
            gr.Markdown("*[Get FREE token](https://huggingface.co/settings/tokens)*")
            
            board_id = gr.Textbox(
                label="ğŸ“‹ Trello Board ID",
                value=DEFAULT_BOARD_ID
            )
            gr.Markdown("*From URL: trello.com/b/**BOARD_ID***")
            
            list_name = gr.Textbox(
                label="ğŸ“ Target List",
                value="AI Generated Tasks"
            )
            
            with gr.Accordion("ğŸ›ï¸ Advanced Options", open=False):
                enable_analytics = gr.Checkbox(
                    label="ğŸ“Š Advanced Analytics",
                    value=True
                )
                enable_labels = gr.Checkbox(
                    label="ğŸ·ï¸ Smart Labels",
                    value=True
                )
                enable_checklists = gr.Checkbox(
                    label="â˜‘ï¸ Checklists",
                    value=True
                )
                enable_insights = gr.Checkbox(
                    label="ğŸ”® AI Insights",
                    value=True
                )
                template = gr.Dropdown(
                    label="ğŸ“‹ Card Template",
                    choices=["default", "detailed", "agile"],
                    value="detailed"
                )
        
        with gr.Column(scale=2):
            gr.Markdown("### ğŸ“ Meeting Input")
            
            meeting_text = gr.Textbox(
                label="Meeting Notes / Transcript",
                placeholder="ğŸ“ OPTIONAL: Paste meeting notes...\n\nOr just upload audio/image below!\n\nExample if using text:\n- John fix login bug by Friday (urgent)\n- Sarah update docs tomorrow\n- Mike review budget next week",
                lines=8
            )
            
            gr.Markdown("### ğŸ¤ OR Upload Audio Recording")
            audio_file = gr.Audio(
                label="Audio (MP3, WAV, M4A, MP4) - max 25MB",
                type="filepath"
            )
            gr.Markdown("*ğŸ’¡ Just upload audio - no text needed!*")
            
            gr.Markdown("### ğŸ“¸ OR Upload Image/Whiteboard") 
            image_file = gr.Image(
                label="Image (JPG, PNG) - screenshots, whiteboards, notes",
                type="filepath"
            )
            gr.Markdown("*ğŸ’¡ Just upload image - no text needed!*")
            
            gr.Markdown("""
            ---
            **âœ¨ Input Options:**
            - ğŸ“ Text only (min 20 chars)
            - ğŸ¤ Audio only
            - ğŸ“¸ Image only  
            - ğŸ¯ Any combination
            """)
            
            process_btn = gr.Button(
                "ğŸš€ PROCESS & CREATE TRELLO CARDS",
                variant="primary",
                size="lg"
            )
    
    with gr.Row():
        with gr.Column():
            gr.Markdown("### ğŸ“‹ Extracted Tasks")
            task_output = gr.Markdown()
        
        with gr.Column():
            gr.Markdown("### ğŸ“Š Analytics & Insights")
            analytics_output = gr.Markdown()
    
    gr.Markdown("### ğŸ¯ Trello Results")
    trello_output = gr.Markdown()
    
    # Example section
    with gr.Accordion("ğŸ’¡ Quick Start Examples", open=False):
        gr.Markdown("""
        ## Try These Examples:
        
        ### Example 1: Simple Meeting Notes
        ```
        Team standup - Nov 11, 2025
        
        - John: Fix the login bug (URGENT - blocking users)
        - Sarah: Update API documentation by Friday
        - Mike: Review Q4 budget (due in 2 weeks)
        - Everyone: Prepare for client demo next Tuesday
        ```
        
        ### Example 2: Detailed Project Planning
        ```
        Product roadmap discussion:
        
        HIGH PRIORITY:
        - Launch new homepage design (Sarah, 2 weeks, 40 hours)
        - Implement payment gateway (John, critical, depends on security audit)
        - Fix mobile responsive issues (Mike, urgent, 8 hours)
        
        MEDIUM PRIORITY:
        - Add user analytics dashboard (3 weeks)
        - Update privacy policy
        - Conduct user testing
        
        BLOCKERS:
        - Waiting for legal approval on terms
        - Need designer feedback on mockups
        ```
        
        ### Example 3: With Audio
        Upload any meeting recording (MP3/WAV/M4A) and the AI will:
        - Transcribe the full conversation
        - Extract action items automatically
        - Identify assignees, deadlines, and priorities
        - Create organized Trello cards
        
        ### Example 4: With Image
        Upload a photo of:
        - Whiteboard brainstorming session
        - Handwritten meeting notes
        - Screenshot of tasks
        - Post-it note board
        
        The AI will analyze and extract actionable tasks!
        """)
    
    # Setup guide
    with gr.Accordion("âš™ï¸ Setup Guide", open=False):
        gr.Markdown("""
        ## ğŸ› ï¸ Quick Setup (5 minutes)
        
        ### 1. HuggingFace Token (FREE)
        1. Go to: [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
        2. Sign up (free account)
        3. Click "New token"
        4. Select "Read" permissions
        5. Copy token starting with `hf_`
        
        ### 2. Trello Setup
        **API Key:**
        - Visit: [trello.com/power-ups/admin](https://trello.com/power-ups/admin)
        - Copy your API key
        
        **Token:**
        - Click: [Get Token](https://trello.com/1/authorize?expiration=never&scope=read,write&response_type=token&name=MeetingAI&key=045608c9286edf8331551c007072df9e)
        - Authorize the app
        - Copy the token
        
        **Board ID:**
        - Open your Trello board
        - Look at URL: `trello.com/b/BOARD_ID/board-name`
        - Copy the BOARD_ID part
        
        ### 3. Test It!
        Paste this in Meeting Notes:
        ```
        Test meeting - Fix homepage bug by Friday (John)
        ```
        Click "PROCESS & CREATE TRELLO CARDS"
        
        ---
        
        ## ğŸ¯ Supported Formats
        
        **Audio:** MP3, WAV, M4A, MP4 (max 25MB)
        **Images:** JPG, PNG, HEIC
        **Text:** Any language (50+ supported)
        
        ## ğŸ”¥ Pro Tips
        
        1. **Audio Quality:** Clear recordings work best
        2. **Be Specific:** Mention names, dates, priorities
        3. **Use Keywords:** "urgent", "ASAP", "by Friday"
        4. **Batch Process:** Upload multiple meetings at once
        5. **Templates:** Use agile template for sprint planning
        """)
    
    # Features showcase
    with gr.Accordion("âœ¨ All Features", open=False):
        gr.Markdown("""
        # ğŸš€ Complete Feature List
        
        ## ğŸ¤ Audio Processing
        - âœ… Multi-format support (MP3, WAV, M4A, MP4)
        - âœ… Whisper AI transcription (99% accuracy)
        - âœ… Automatic fallback models
        - âœ… Speaker diarization hints
        - âœ… 50+ languages supported
        
        ## ğŸ“¸ Image Analysis
        - âœ… OCR + AI Vision combined
        - âœ… Whiteboard recognition
        - âœ… Handwriting detection
        - âœ… Screenshot parsing
        - âœ… Document extraction
        
        ## ğŸ§  AI Task Extraction
        - âœ… GPT-4 level intelligence
        - âœ… Context understanding
        - âœ… Priority detection (critical â†’ low)
        - âœ… Deadline extraction (relative dates)
        - âœ… Assignee identification
        - âœ… Time estimation
        - âœ… Dependency mapping
        - âœ… Blocker detection
        - âœ… Success criteria
        - âœ… Business value analysis
        - âœ… Risk assessment
        
        ## ğŸ¯ Trello Integration
        - âœ… Smart card creation
        - âœ… Auto-labeling (priority, effort, category)
        - âœ… Due date calculation
        - âœ… Member assignment (smart matching)
        - âœ… Checklist generation
        - âœ… Dependency tracking
        - âœ… Rich descriptions
        - âœ… Multiple templates (default, detailed, agile)
        
        ## ğŸ“Š Analytics & Insights
        - âœ… Priority distribution
        - âœ… Workload analysis
        - âœ… Team capacity planning
        - âœ… Timeline tracking
        - âœ… Risk assessment
        - âœ… Bottleneck detection
        - âœ… AI recommendations
        - âœ… Meeting statistics
        
        ## ğŸ¨ Templates
        - âœ… Default (clean & simple)
        - âœ… Detailed (enterprise-grade)
        - âœ… Agile (sprint planning ready)
        
        ## ğŸ”’ Enterprise Ready
        - âœ… Secure token handling
        - âœ… Error recovery
        - âœ… Rate limit management
        - âœ… Batch operations
        - âœ… Conflict resolution
        """)
    
    # Connect button
    process_btn.click(
        fn=process_all,
        inputs=[
            meeting_text, audio_file, image_file,
            hf_token, board_id, list_name,
            enable_analytics, enable_labels, enable_checklists,
            enable_insights, template
        ],
        outputs=[task_output, analytics_output, trello_output]
    )

if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,
        show_error=True
    )